[
  {
    "model_benchmark_id": 1400,
    "benchmark_id": "fleurs",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.864,
    "normalized_score": 0.864,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Speech recognition accuracy (1 - WER)",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.951665+00:00",
    "updated_at": "2025-07-19T19:56:13.951665+00:00",
    "benchmark_name": "FLEURS"
  },
  {
    "model_benchmark_id": 277,
    "benchmark_id": "gpqa",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.384,
    "normalized_score": 0.384,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Accuracy on expert-written science questions",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.635441+00:00",
    "updated_at": "2025-07-19T19:56:11.635441+00:00",
    "benchmark_name": "GPQA"
  },
  {
    "model_benchmark_id": 1163,
    "benchmark_id": "hiddenmath",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.328,
    "normalized_score": 0.328,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Accuracy on competition-level math problems",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.447290+00:00",
    "updated_at": "2025-07-19T19:56:13.447290+00:00",
    "benchmark_name": "HiddenMath"
  },
  {
    "model_benchmark_id": 387,
    "benchmark_id": "math",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.587,
    "normalized_score": 0.587,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Accuracy on mathematical problem-solving tasks",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.834192+00:00",
    "updated_at": "2025-07-19T19:56:11.834192+00:00",
    "benchmark_name": "MATH"
  },
  {
    "model_benchmark_id": 519,
    "benchmark_id": "mathvista",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.547,
    "normalized_score": 0.547,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Visual mathematical reasoning accuracy",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:12.078820+00:00",
    "updated_at": "2025-07-19T19:56:12.078820+00:00",
    "benchmark_name": "MathVista"
  },
  {
    "model_benchmark_id": 173,
    "benchmark_id": "mmlu-pro",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.587,
    "normalized_score": 0.587,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Multiple choice accuracy across enhanced MMLU dataset with higher difficulty tasks",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.436045+00:00",
    "updated_at": "2025-07-19T19:56:11.436045+00:00",
    "benchmark_name": "MMLU-Pro"
  },
  {
    "model_benchmark_id": 561,
    "benchmark_id": "mmmu",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.537,
    "normalized_score": 0.537,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Multimodal understanding accuracy",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:12.154594+00:00",
    "updated_at": "2025-07-19T19:56:12.154594+00:00",
    "benchmark_name": "MMMU"
  },
  {
    "model_benchmark_id": 1377,
    "benchmark_id": "mrcr",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.547,
    "normalized_score": 0.547,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Long-context comprehension accuracy",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.898262+00:00",
    "updated_at": "2025-07-19T19:56:13.898262+00:00",
    "benchmark_name": "MRCR"
  },
  {
    "model_benchmark_id": 1203,
    "benchmark_id": "natural2code",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.755,
    "normalized_score": 0.755,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Pass rate on code generation tasks across multiple programming languages",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.531432+00:00",
    "updated_at": "2025-07-19T19:56:13.531432+00:00",
    "benchmark_name": "Natural2Code"
  },
  {
    "model_benchmark_id": 1370,
    "benchmark_id": "vibe-eval",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.409,
    "normalized_score": 0.409,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Visual understanding evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.885058+00:00",
    "updated_at": "2025-07-19T19:56:13.885058+00:00",
    "benchmark_name": "Vibe-Eval"
  },
  {
    "model_benchmark_id": 1382,
    "benchmark_id": "video-mme",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.662,
    "normalized_score": 0.662,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Video analysis accuracy",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.910273+00:00",
    "updated_at": "2025-07-19T19:56:13.910273+00:00",
    "benchmark_name": "Video-MME"
  },
  {
    "model_benchmark_id": 1396,
    "benchmark_id": "wmt23",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.726,
    "normalized_score": 0.726,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Translation quality score",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.942779+00:00",
    "updated_at": "2025-07-19T19:56:13.942779+00:00",
    "benchmark_name": "WMT23"
  },
  {
    "model_benchmark_id": 1420,
    "benchmark_id": "xstest",
    "model_id": "gemini-1.5-flash-8b",
    "score": 0.926,
    "normalized_score": 0.926,
    "is_self_reported": true,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "verified_by_llmstats": false,
    "analysis_method": "Safe request fulfillment rate",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.005888+00:00",
    "updated_at": "2025-07-19T19:56:14.005888+00:00",
    "benchmark_name": "XSTest"
  }
]