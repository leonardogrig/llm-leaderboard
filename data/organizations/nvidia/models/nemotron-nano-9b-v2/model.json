{
  "model_id": "nvidia-nemotron-nano-9b-v2",
  "name": "Nemotron Nano 9B v2",
  "organization_id": "nvidia",
  "fine_tuned_from_model_id": null,
  "description": "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. The model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so, albeit with a slight decrease in accuracy for harder prompts that require reasoning. Conversely, allowing the model to generate reasoning traces first generally results in higher-quality final solutions to queries and tasks.",
  "release_date": "2025-08-18",
  "announcement_date": "2025-08-18",
  "license_id": "nvidia_open_model_license_agreement",
  "multimodal": false,
  "knowledge_cutoff": "2024-09",
  "param_count": 88900000000,
  "training_tokens": 21100000000000,
  "available_in_zeroeval": true,
  "source_api_ref": null,
  "source_playground": "https://build.nvidia.com/nvidia/nvidia-nemotron-nano-9b-v2",
  "source_paper": "https://arxiv.org/abs/2508.14444",
  "source_scorecard_blog_link": "https://build.nvidia.com/nvidia/nvidia-nemotron-nano-9b-v2/modelcard",
  "source_repo_link": null,
  "source_weights_link": "https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2",
  "created_at": "2025-10-02T21:51:16.835+00:00",
  "updated_at": "2025-10-02T21:51:16.835+00:00",
  "model_family_id": null
}