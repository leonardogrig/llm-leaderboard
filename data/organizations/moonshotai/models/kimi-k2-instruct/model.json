{
  "model_id": "kimi-k2-instruct",
  "name": "Kimi K2 Instruct",
  "organization_id": "moonshotai",
  "fine_tuned_from_model_id": "kimi-k2-base",
  "description": "Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters. Trained with the MuonClip optimizer, it achieves exceptional performance across frontier knowledge, reasoning, and coding tasks while being meticulously optimized for agentic capabilities. The instruct variant is post-trained for drop-in, general-purpose chat and agentic experiences without long thinking.",
  "release_date": "2025-01-01",
  "announcement_date": "2025-01-01",
  "license_id": "mit",
  "multimodal": false,
  "knowledge_cutoff": null,
  "param_count": 1000000000000,
  "training_tokens": 15500000000000,
  "available_in_zeroeval": true,
  "source_api_ref": "https://platform.moonshot.ai",
  "source_playground": "https://kimi.com",
  "source_paper": null,
  "source_scorecard_blog_link": "https://moonshotai.github.io/Kimi-K2/",
  "source_repo_link": "https://github.com/MoonshotAI/Kimi-K2",
  "source_weights_link": "https://huggingface.co/moonshotai/Kimi-K2-Instruct",
  "created_at": "2025-07-19T19:49:05.875884+00:00",
  "updated_at": "2025-07-19T19:49:05.875884+00:00",
  "model_family_id": null
}
